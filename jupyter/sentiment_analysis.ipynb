{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a5621ac-a2b7-489b-8a7b-d4240420badd",
   "metadata": {},
   "source": [
    "# DMG Mori Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30afbc78-9fe3-4c5f-a0a7-664daeed7468",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f004ed84-24e4-4790-9a73-e753efedc30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3 \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import torch\n",
    "import tweetnlp\n",
    "from scipy.special import softmax\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255712c5-aae8-4cb2-8f18-33f4431ffa89",
   "metadata": {},
   "source": [
    "## util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0431a30e-7eae-48d7-b6df-0bbfd48fcd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_s3(access_key: str, secret_key: str, region: str):\n",
    "    print(\"connecting to S3\")\n",
    "    return boto3.resource(\n",
    "            service_name='s3',\n",
    "            region_name=region,\n",
    "            aws_access_key_id=access_key,\n",
    "            aws_secret_access_key=secret_key\n",
    "    )\n",
    "\n",
    "    \n",
    "def read_json(path_to_file: str):\n",
    "    with open(path_to_file) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def read_dataframe_from_s3(bucket_name: str, file_name: str):\n",
    "    s3 = connect_to_s3(access_key=access_key, \n",
    "                       secret_key=secret_key,\n",
    "                       region=region)\n",
    "    try:\n",
    "        s3_object_response = s3.Bucket(bucket_name).Object(file_name).get()\n",
    "        print(f\"Succesfully read {filename} from S3\")\n",
    "        return pd.read_csv(s3_object_response[\"Body\"], index_col=0)\n",
    "    except:\n",
    "        print(\"Error: check connection or file name\")\n",
    "\n",
    "def upload_dataframe_to_s3(df, bucket_name, access_key, secret_key, folder_name, file_name):\n",
    "    df.to_csv(file_name)\n",
    "    s3 = connect_to_s3(access_key=access_key, \n",
    "                           secret_key=secret_key,\n",
    "                           region=region) \n",
    "    try:\n",
    "        s3.Bucket(bucket_name).upload_file(Filename=file_name, Key=(folder_name+file_name))\n",
    "        print(\"Successfully uploaded!!\")\n",
    "    except:\n",
    "        print(\"Failed to upload file!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2459dd13-cac2-400d-919d-d64394882c36",
   "metadata": {},
   "source": [
    "## Secret keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d6beff7-5c4e-47e8-a558-57890a30f60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "secret = read_json(path_to_file=\"../secret.json\")\n",
    "access_key = secret[\"access_key\"]\n",
    "secret_key = secret[\"secret_key\"]\n",
    "bucket_name = secret[\"bucket_name\"]\n",
    "region = secret[\"region\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e836b7-4afd-4f0a-9664-08e4a3642213",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9979d21a-dbf4-4700-b581-ca14e3e30170",
   "metadata": {},
   "outputs": [],
   "source": [
    "linkedin_df_url = \"https://phantombuster.s3.amazonaws.com/UhrenaxfEnY/ufbCwx76csm5U7tZEWDzTg/dmg_mori_linkedin_comments.csv\"\n",
    "facebook_df_url = \"dmg_mori_facebook_comments.csv\"\n",
    "insta_df_url = \"https://phantombuster.s3.amazonaws.com/UhrenaxfEnY/mVSiBkjqgmmHPyNuoDJMzQ/mori_instagram_comments.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdec7470-cca2-47ee-8ffe-597accedcf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = connect_to_s3(access_key=access_key, \n",
    "                   secret_key=secret_key,\n",
    "                   region=region)\n",
    "\n",
    "facebook_df = read_dataframe_from_s3(bucket_name=bucket_name, file_name=facebook_df_url)\n",
    "linkedin_df = pd.read_csv(linkedin_df_url)\n",
    "insta_df = pd.read_csv(insta_df_url)\n",
    "facebook_df = facebook_df.rename(columns={\"text\": \"comment\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36445186-ac74-43d2-8fbb-503eac16f8b3",
   "metadata": {},
   "source": [
    "### Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a068da28-8795-4c82-828d-a9c59534b397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size:600, missing comments:55\n",
      "dataset size:1249, missing comments:17\n",
      "dataset size:1083, missing comments:6\n"
     ]
    }
   ],
   "source": [
    "dataset_list = [facebook_df, linkedin_df, insta_df]\n",
    "for dataset in dataset_list:\n",
    "    print(f\"dataset size:{len(dataset)}, missing comments:{dataset['comment'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6e8e274-d8e0-41af-9f52-9a872c3303d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "facebook_df = facebook_df.dropna(subset=[\"comment\"])\n",
    "linkedin_df = linkedin_df.dropna(subset=[\"comment\"])\n",
    "insta_df = insta_df.dropna(subset=[\"comment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6367fd7-e219-41b9-9ebc-2808007d0fba",
   "metadata": {},
   "source": [
    "### Filtering data for the year 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21988dfc-5fa5-4a37-bb46-2cdb999e44b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['postDescription', 'comment', 'likesCount', 'facebookUrl', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facebook_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0dd549c5-b3cf-47f2-8a39-781c956d3bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['profileLink', 'firstName', 'lastName', 'fullName', 'occupation',\n",
       "       'degree', 'comment', 'commentUrl', 'isFromPostAuthor', 'commentDate',\n",
       "       'likesCount', 'postUrl', 'timestamp', 'companyUrl', 'companyName',\n",
       "       'followersCount', 'error', 'sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkedin_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33803e1b-a7ba-4ba9-afc8-41f79d8f0c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/3n8hkzp95lb4p46__fg4vpx00000gs/T/ipykernel_65001/2479198543.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  linkedin_df[\"commentDate\"] = pd.to_datetime(linkedin_df[\"commentDate\"])\n"
     ]
    }
   ],
   "source": [
    "linkedin_df[\"commentDate\"] = pd.to_datetime(linkedin_df[\"commentDate\"])\n",
    "linkedin_df = linkedin_df[linkedin_df[\"commentDate\"] >= \"2023-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c26144c3-c0b5-46ad-9067-55389098713e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/3n8hkzp95lb4p46__fg4vpx00000gs/T/ipykernel_65001/2738066305.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  insta_df[\"commentDate\"] = pd.to_datetime(insta_df[\"commentDate\"])\n"
     ]
    }
   ],
   "source": [
    "insta_df[\"commentDate\"] = pd.to_datetime(insta_df[\"commentDate\"])\n",
    "insta_df = insta_df[insta_df[\"commentDate\"] >= \"2023-01-01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98a1599-a520-4935-a8c5-748b67499574",
   "metadata": {},
   "source": [
    "## Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4e39491-99c9-4422-95ef-1aa0c24dc997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10c37b1-6f14-40fc-8396-70377c0f20af",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85fdf8ec-6b06-4f2d-af54-3a94efbcb0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiments(text):\n",
    "    try: \n",
    "        encoded_input = tokenizer(text, return_tensors='pt')\n",
    "        output = model(**encoded_input)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        ranking = np.argsort(scores)\n",
    "        ranking = ranking[::-1]\n",
    "        sentiment = config.id2label[ranking[0]]\n",
    "        return sentiment\n",
    "    except:\n",
    "        return \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2dd9bc17-7aa2-427e-9039-cf71d2552769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/3n8hkzp95lb4p46__fg4vpx00000gs/T/ipykernel_65001/3695360073.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  linkedin_df[\"sentiment\"] = linkedin_df[\"comment\"].apply(get_sentiments)\n"
     ]
    }
   ],
   "source": [
    "facebook_df[\"sentiment\"] = facebook_df[\"comment\"].apply(get_sentiments)\n",
    "linkedin_df[\"sentiment\"] = linkedin_df[\"comment\"].apply(get_sentiments)\n",
    "insta_df[\"sentiment\"] = insta_df[\"comment\"].apply(get_sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ea9720-1691-48a4-933b-99b817301543",
   "metadata": {},
   "source": [
    "### Topic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3c1cc951-e226-4943-b28f-f373a04f1b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tokenizer_config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:00<00:00, 291kB/s]\n",
      "Downloading vocab.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 780k/780k [00:00<00:00, 2.83MB/s]\n",
      "Downloading merges.txt: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 446k/446k [00:00<00:00, 1.99MB/s]\n",
      "Downloading tokenizer.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.29M/1.29M [00:00<00:00, 3.19MB/s]\n",
      "Downloading special_tokens_map.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 239/239 [00:00<00:00, 269kB/s]\n",
      "Downloading config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.96k/1.96k [00:00<00:00, 5.91MB/s]\n",
      "Downloading pytorch_model.bin: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 476M/476M [00:45<00:00, 10.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['film_tv_&_video', 'music']\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-dec2021-tweet-topic-multi-all\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-dec2021-tweet-topic-multi-all\", problem_type=\"multi_label_classification\")\n",
    "model.eval()\n",
    "class_mapping = model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "677f8266-9967-420a-8a3b-0d8a31abbd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic(text: str):\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            tokens = tokenizer(text, return_tensors='pt')\n",
    "            output = model(**tokens)\n",
    "            topic_probs = [sigmoid(x) for x in output[0][0].detach().tolist()]\n",
    "        return class_mapping[np.argmax(topic_probs)]\n",
    "    except:\n",
    "        print(text)\n",
    "        return \"others\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ca4c349e-1e75-4902-8fc8-6cf63284813e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FB-Elaine Hsieh 是私人帳號, 如果您想要在我的帳號貼文, 請您依照正常管道進行貼文(1). 請您進入 www.elainehsieh.tw “會員系統”填寫您的會員資料. (2). 請您進入 “訂單填寫” (3). 請您使用信用卡-聯銀卡繳款或是 ATM/銀行 轉帳 (4).當我們收到您的訊息之後, 我們會立刻將您的貼文轉貼至您指定的粉絲群-限時動態/Reels (5). 一旦我們作業完成, 我們會使用 Messenger/ 留言/Email 通知您.這樣就算是完成作業!\n",
      "\n",
      "FB-Elaine Hsieh is a private account, if you want to post on my account, please follow the normal channels to post (1). Please visit ww.elainehsieh.tw \"Member System\" to fill in your membership information. (2). Please go to \"Order Filling\" (3). Please use credit card - Union Bank card payment or ATM/bank transfer (4).When we receive your message, we will immediately post your post into your designated base - Limited Time News/Reels (5). Once our assignment is complete, we will notify you using Messenger/Message/Email. This is complete work.\n"
     ]
    }
   ],
   "source": [
    "facebook_df[\"topic\"] = facebook_df[\"comment\"].apply(get_topic)\n",
    "linkedin_df[\"topic\"] = linkedin_df[\"comment\"].apply(get_topic)\n",
    "insta_df[\"topic\"] = insta_df[\"comment\"].apply(get_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f6e032-f85f-4972-ab44-6c1b7eac977a",
   "metadata": {},
   "source": [
    "## sentiment distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "323860aa-d768-4cf5-b2d8-0467524154bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative     11\n",
       "neutral     296\n",
       "positive    238\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facebook_df.groupby('sentiment').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "20de9742-06e7-4d1b-a76a-7242cb389d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative     30\n",
       "neutral     422\n",
       "positive    600\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkedin_df.groupby('sentiment').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "497a04cd-aa4d-433e-9731-ee087b869da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative     62\n",
       "neutral     272\n",
       "positive    743\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insta_df.groupby('sentiment').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749b0c8f-6293-4d8b-8c08-a30e0c87848f",
   "metadata": {},
   "source": [
    "## Topic Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "efbae499-5956-48df-8cd7-c1fb4f79e001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment  topic                   \n",
       "negative   business_&_entrepreneurs      3\n",
       "           diaries_&_daily_life          1\n",
       "           news_&_social_concern         1\n",
       "           science_&_technology          5\n",
       "           sports                        1\n",
       "neutral    business_&_entrepreneurs     22\n",
       "           celebrity_&_pop_culture      25\n",
       "           diaries_&_daily_life        113\n",
       "           fashion_&_style               4\n",
       "           film_tv_&_video              16\n",
       "           fitness_&_health              1\n",
       "           food_&_dining                 2\n",
       "           gaming                        2\n",
       "           learning_&_educational        2\n",
       "           music                        17\n",
       "           news_&_social_concern        23\n",
       "           other_hobbies                 9\n",
       "           others                        1\n",
       "           science_&_technology         17\n",
       "           sports                       42\n",
       "positive   arts_&_culture                1\n",
       "           business_&_entrepreneurs     10\n",
       "           celebrity_&_pop_culture       9\n",
       "           diaries_&_daily_life        154\n",
       "           fashion_&_style               4\n",
       "           film_tv_&_video               7\n",
       "           gaming                        4\n",
       "           music                         3\n",
       "           news_&_social_concern         3\n",
       "           other_hobbies                 6\n",
       "           relationships                 2\n",
       "           science_&_technology         23\n",
       "           sports                       12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facebook_df.groupby(['sentiment', 'topic']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "66af85fe-2982-469a-8a3e-a36c505edd6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment  topic                   \n",
       "negative   business_&_entrepreneurs      2\n",
       "           diaries_&_daily_life          9\n",
       "           film_tv_&_video               2\n",
       "           fitness_&_health              4\n",
       "           news_&_social_concern         2\n",
       "           science_&_technology          7\n",
       "           sports                        4\n",
       "neutral    arts_&_culture                1\n",
       "           business_&_entrepreneurs     32\n",
       "           celebrity_&_pop_culture      19\n",
       "           diaries_&_daily_life        124\n",
       "           fashion_&_style               3\n",
       "           film_tv_&_video               9\n",
       "           fitness_&_health              6\n",
       "           food_&_dining                 5\n",
       "           gaming                       13\n",
       "           music                        10\n",
       "           news_&_social_concern        21\n",
       "           other_hobbies                 8\n",
       "           science_&_technology        116\n",
       "           sports                       54\n",
       "           travel_&_adventure            1\n",
       "positive   arts_&_culture                1\n",
       "           business_&_entrepreneurs     55\n",
       "           celebrity_&_pop_culture      10\n",
       "           diaries_&_daily_life        235\n",
       "           fashion_&_style              15\n",
       "           film_tv_&_video              23\n",
       "           food_&_dining                 3\n",
       "           gaming                        5\n",
       "           learning_&_educational        1\n",
       "           music                        11\n",
       "           news_&_social_concern         3\n",
       "           other_hobbies                23\n",
       "           relationships                 1\n",
       "           science_&_technology        167\n",
       "           sports                       47\n",
       "dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkedin_df.groupby(['sentiment', 'topic']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bb5fe29a-cced-434d-8634-42bb2ce3d70c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment  topic                   \n",
       "negative   business_&_entrepreneurs      4\n",
       "           celebrity_&_pop_culture       2\n",
       "           diaries_&_daily_life         10\n",
       "           gaming                        1\n",
       "           news_&_social_concern        34\n",
       "           science_&_technology          9\n",
       "           sports                        2\n",
       "neutral    arts_&_culture                1\n",
       "           business_&_entrepreneurs     21\n",
       "           celebrity_&_pop_culture      12\n",
       "           diaries_&_daily_life         90\n",
       "           fashion_&_style               1\n",
       "           film_tv_&_video               9\n",
       "           fitness_&_health              2\n",
       "           food_&_dining                 3\n",
       "           gaming                       12\n",
       "           music                         8\n",
       "           news_&_social_concern        22\n",
       "           other_hobbies                 5\n",
       "           science_&_technology         49\n",
       "           sports                       37\n",
       "positive   arts_&_culture                1\n",
       "           business_&_entrepreneurs     30\n",
       "           celebrity_&_pop_culture      15\n",
       "           diaries_&_daily_life        340\n",
       "           fashion_&_style              65\n",
       "           film_tv_&_video              30\n",
       "           food_&_dining                 2\n",
       "           gaming                        9\n",
       "           learning_&_educational        1\n",
       "           music                        11\n",
       "           news_&_social_concern         3\n",
       "           other_hobbies                11\n",
       "           relationships                 5\n",
       "           science_&_technology         59\n",
       "           sports                      161\n",
       "dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insta_df.groupby(['sentiment', 'topic']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d4305a-9f24-4e77-805c-0b5ffe6e8339",
   "metadata": {},
   "source": [
    "## Save the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2798bf41-c232-4761-9b5c-d1718230d93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function upload_dataframe_to_s3 in module __main__:\n",
      "\n",
      "upload_dataframe_to_s3(df, bucket_name, folder_name, file_name)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(upload_dataframe_to_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "006d1b3b-11f1-4661-ab7b-4ff841ff8bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaushikdayalan/projects/storymachine_projects/dmg_mori_sentiment_analysis/.env/lib/python3.9/site-packages/pandas/core/internals/blocks.py:2540: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting to S3\n",
      "Successfully uploaded!!\n",
      "connecting to S3\n",
      "Successfully uploaded!!\n",
      "connecting to S3\n",
      "Successfully uploaded!!\n"
     ]
    }
   ],
   "source": [
    "folder_name = \"output/\"\n",
    "facebook_file_name = \"dmg_mori_facbook_2023_sentiments.csv\"\n",
    "linkedin_file_name = \"dmg_mori_linkedin_2023_sentiments.csv\"\n",
    "insta_file_name = \"dmg_mori_insta_2023_sentiments.csv\"\n",
    "\n",
    "upload_dataframe_to_s3(df=facebook_df, access_key=access_key, secret_key=secret_key, bucket_name=bucket_name, file_name=facebook_file_name, folder_name=folder_name)\n",
    "upload_dataframe_to_s3(df=linkedin_df, access_key=access_key, secret_key=secret_key, bucket_name=bucket_name, file_name=linkedin_file_name, folder_name=folder_name)\n",
    "upload_dataframe_to_s3(df=insta_df, access_key=access_key, secret_key=secret_key, bucket_name=bucket_name, file_name=insta_file_name, folder_name=folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dde2ca-df06-4790-b0af-04b54e880a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
